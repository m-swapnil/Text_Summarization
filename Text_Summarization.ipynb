{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfd6925",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dee53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Swapnil\n",
      "[nltk_data]     Mishra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcafd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ac5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english') + list(punctuation))\n",
    "MIN_WORD_PROP, MAX_WORD_PROP = 0.05, 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a104fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences: 21\n",
      "Summary (3 sentences): ['‘you had better come and live here, frodo my lad,’ said bilbo one day; ‘and then we can celebrate our birthday-parties comfortably together.’ at that time frodo was still in his tweens, as the hobbits called the irresponsible twenties between childhood and coming of age at thirty-three.', 'bilbo was going to be eleventy-one, 111, a rather curious number and a very respectable age for a hobbit (the old took himself had only reached 130); and frodo was going to be thirty-three, 33) an important number: the date of his ‘coming of age’.', 'when mr. bilbo baggins of bag end announced that he would shortly be celebrating his eleventy-first birthday with a party of special magnificence, there was much talk and excitement in hobbiton.']\n",
      "Summary (1 sentence): ['‘you had better come and live here, frodo my lad,’ said bilbo one day; ‘and then we can celebrate our birthday-parties comfortably together.’ at that time frodo was still in his tweens, as the hobbits called the irresponsible twenties between childhood and coming of age at thirty-three.']\n"
     ]
    }
   ],
   "source": [
    "def compute_word_frequencies(word_sentences):\n",
    "    words = [word for sentence in word_sentences\n",
    "                    for word in sentence\n",
    "                        if word not in STOPWORDS]\n",
    "    counter = Counter(words)\n",
    "    limit = float(max(counter.values()))\n",
    "    word_frequencies = {word: freq/limit\n",
    "                                   for word, freq in counter.items()}\n",
    "    # Drop words if too common or too uncommon\n",
    "    word_frequencies = {word:freq\n",
    "                           for word,freq in word_frequencies.items()\n",
    "                               if freq > MIN_WORD_PROP\n",
    "                               and freq < MAX_WORD_PROP}\n",
    "    return word_frequencies\n",
    "\n",
    "def sentence_score(word_sentence, word_frequencies):\n",
    "    return sum([word_frequencies.get(word,0)\n",
    "                    for word in word_sentence])\n",
    "\n",
    "\n",
    "def summarize(text:str, num_sentences = 3):\n",
    "    '''\n",
    "    Summarize the text, return the most relevant sentences\n",
    "    :text the text to summarize\n",
    "    :num_sentences the number of sentences to return\n",
    "    '''\n",
    "    text = text.lower() # Make the text lowercase\n",
    "    sentences = sent_tokenize(text) # Breaks texts into sentences\n",
    "    \n",
    "    # Break sentences into words\n",
    "    word_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # COmpute word frequencies\n",
    "    word_frequencies = compute_word_frequencies(word_sentences)\n",
    "    \n",
    "    # Calculate the scores for each of the sentences\n",
    "    scores = [sentence_score(word_sentence, word_frequencies) for word_sentence in word_sentences]\n",
    "    sentence_scores = list(zip(sentences, scores))\n",
    "    \n",
    "    # Rank the sentences\n",
    "    top_sentence_scores = nlargest(num_sentences, sentence_scores, key = lambda t: t[1])\n",
    "    \n",
    "    # Return the top sentences\n",
    "    return[t[0] for t in top_sentence_scores]\n",
    "    \n",
    "with open(\"C:/Users/Swapnil Mishra/Desktop/DS/Text Mining/Text Summarization/Lordoftherings.txt\",'r',encoding='utf-8') as file:\n",
    "    lor = file.read()\n",
    "    \n",
    "# Cleaned text\n",
    "lor = lor.replace('\\n', ' ').strip()\n",
    "\n",
    "# Summarize\n",
    "print(f\"Total Sentences: {len(sent_tokenize(lor))}\")\n",
    "print(\"Summary (3 sentences):\", summarize(lor))\n",
    "print(\"Summary (1 sentence):\", summarize(lor, num_sentences=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77fddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count Before Summarization: 575\n",
      "Word Count After Summarization: 145\n"
     ]
    }
   ],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"Count the number of words in the text.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)\n",
    "\n",
    "# Count words before summarization\n",
    "original_word_count = count_words(lor)\n",
    "\n",
    "# Get the summary\n",
    "summary = summarize(lor, num_sentences=3)\n",
    "\n",
    "# Count words after summarization\n",
    "summary_word_count = count_words(' '.join(summary))\n",
    "\n",
    "# Print results\n",
    "print(f\"Word Count Before Summarization: {original_word_count}\")\n",
    "print(f\"Word Count After Summarization: {summary_word_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
